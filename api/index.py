import pandas as pd
from typing import Optional, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
from dotenv import load_dotenv
import json
import os
from openai import OpenAI
load_dotenv() 

# --- ì „ì—­ ë³€ìˆ˜ ---
predictions_db: Optional[pd.DataFrame] = None
# âœ… ìˆ˜ì • 1: Vercel í™˜ê²½ì— ë§ê²Œ íŒŒì¼ ê²½ë¡œë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
PREDICTIONS_PATH = "https://d2dx6c0kdbtt7tfe.public.blob.vercel-storage.com/predictions_2025.csv"

# --- CBS ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ---
def map_commercial_change_indicator(indicator_name: str) -> int:
    mapping = {'ìƒê¶Œì¶•ì†Œ': 1, 'ì •ì²´': 2, 'í™œì„±í™”': 3, 'ë‹¤ì´ë‚˜ë¯¹': 4}
    return mapping.get(indicator_name, 1)
 
def normalize(series: pd.Series) -> pd.Series:
    """Pandas Seriesë¥¼ 0-100 ì‚¬ì´ ê°’ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    min_val = series.min()
    max_val = series.max()
    if max_val - min_val == 0:
        return pd.Series(50, index=series.index)
    return 100 * (series - min_val) / (max_val - min_val)

def calculate_cbs_scores(df):
    seoul_avg_op_months = df['ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ']
    df['stability_index'] = (1 - df['íì—…_ë¥ ']) * 100 * (df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / seoul_avg_op_months)
    change_indicator_vals = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…'].apply(map_commercial_change_indicator)
    df['growth_index'] = np.where(
        df['íì—…_ë¥ '] == 0, 0,
        (df['ê°œì—…_ìœ¨'] / df['íì—…_ë¥ ']) * change_indicator_vals * 100
    )
    df['location_advantage_index'] = np.where(
        df['ì í¬_ìˆ˜'] == 0, 0,
        (df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / df['ì í¬_ìˆ˜']) * (df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
    )
    df['sales_norm'] = normalize(df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'])
    df['stability_norm'] = normalize(df['stability_index'])
    df['growth_norm'] = normalize(df['growth_index'])
    df['location_norm'] = normalize(df['location_advantage_index'])
    df['cbs_raw_score'] = (
        df['sales_norm'] * 0.35 +
        df['stability_norm'] * 0.25 +
        df['growth_norm'] * 0.20 +
        df['location_norm'] * 0.20
    )        
    df['cbs_score'] = normalize(df['cbs_raw_score'])
    df = df.drop(columns=['cbs_raw_score'])
    return df

# --- ì„œë²„ ì‹œì‘/ì¢…ë£Œ ë¡œì§ (ìˆ˜ì • ì—†ìŒ) ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„° ë¡œë“œ ë° ëª¨ë“  ì ìˆ˜ ì‚¬ì „ ê³„ì‚°"""
    global predictions_db, numeric_features
    try:
        df = pd.read_csv(PREDICTIONS_PATH)
        df.fillna(0, inplace=True)
        growth_map = {'ìƒê¶Œí™•ì¥': 1.5, 'ë‹¤ì´ë‚˜ë¯¹': 1.2, 'ì •ì²´': 1.0, 'ìƒê¶Œì¶•ì†Œ': 0.8}
        df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ'].map(growth_map)
        predictions_db = calculate_cbs_scores(df)
        numeric_features = predictions_db.select_dtypes(include=np.number).columns.tolist()
        print("ğŸš€ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ì„œë²„ ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        predictions_db = None
    yield
    print("Application Shutdown.")

# --- ì•± ìƒì„±, CORS, Pydantic ëª¨ë¸ (ìˆ˜ì • ì—†ìŒ) ---
origins = ["*"] # Vercel ë°°í¬ ì‹œì—ëŠ” íŠ¹ì • í”„ë¡ íŠ¸ì—”ë“œ ë„ë©”ì¸ìœ¼ë¡œ ì œí•œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
app = FastAPI(title="HotSpot API", version="0.4", description="ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë° ì •ê·œí™”ëœ CBS ê¸°ë°˜ ì¶”ì²œ API", lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=origins, allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
class RecommendationItem(BaseModel):
    name: str; code: str; cbs_score: float; store_count: int 
class PredictSelectionPayload(BaseModel):
    dong_code: str; industry_code: str

# --- API ë¼ìš°í„° (ìˆ˜ì • ì—†ìŒ) ---
@app.get("/api") # Vercelì—ì„œ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì¸ì‹í•˜ë„ë¡ ìˆ˜ì •
def health_check():
    return {"status": "ok", "prediction_data_ready": predictions_db is not None}

@app.post("/api/predict_by_selection")
def predict_by_selection(payload: PredictSelectionPayload):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤(ì˜ˆì¸¡ DB)ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    result_row = predictions_db[
        (predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(payload.dong_code)) &
        (predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == payload.industry_code)
    ]
    
    if result_row.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    data = result_row.iloc[0]

    return {
        "dong_code": payload.dong_code, 
        "industry_code": payload.industry_code,
        "prediction": round(float(data['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']), 1),
        "cbs_score": round(float(data['cbs_score']), 2),
        "rent": round(float(data['ì„ëŒ€ë£Œ']), 2)
    }

@app.get("/api/rent_distribution")
def get_rent_distribution(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ"), industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    dong_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    if dong_df.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_code}' ì§€ì—­ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    all_rents = predictions_db['ì„ëŒ€ë£Œ'].dropna()
    if all_rents.empty:
        return {"bins": [], "counts": [], "current_rent_bin_index": -1, "current_rent": 0, "top_percentile": 50}

    current_selection_df = dong_df[dong_df['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    current_rent = current_selection_df.iloc[0].get('ì„ëŒ€ë£Œ', 0) if not current_selection_df.empty else 0

    if len(all_rents) > 0:
        count_lower = (all_rents < current_rent).sum()
        percentile_from_bottom = (count_lower / len(all_rents)) * 100
        top_percentile = 100.0 - percentile_from_bottom
    else:
        top_percentile = 50.0

    counts, bins = np.histogram(all_rents, bins=10)
    current_rent_bin_index = np.digitize(current_rent, bins) - 1
    if current_rent_bin_index == len(counts):
        current_rent_bin_index -= 1

    return {
        "bins": bins.tolist(),
        "counts": counts.tolist(),
        "current_rent_bin_index": int(current_rent_bin_index),
        "current_rent": int(current_rent),
        "top_percentile": round(top_percentile, 1)
    }
    
@app.get("/api/recommend/regions")
def get_top_regions_for_industry(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    filtered_df = predictions_db[predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{industry_code}' ì—…ì¢… ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)
    
    return [
        RecommendationItem(name=row['í–‰ì •ë™_ì½”ë“œ_ëª…'], 
                           code=str(row['í–‰ì •ë™_ì½”ë“œ']), 
                           cbs_score=round(row['cbs_score'], 2),
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0) 
        for _, row in top_5.iterrows()
    ]

@app.get("/api/recommend/industries")
def get_top_industries_for_region(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    filtered_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_code}' ì§€ì—­ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)

    return [
        RecommendationItem(name=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'], 
                           code=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'], 
                           cbs_score=round(row['cbs_score'], 2),
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0)
        for _, row in top_5.iterrows()
    ]

@app.get("/api/get_insight")
def get_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    import shap
    
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    features_to_exclude = [
        'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡',
        'stability_index', 'growth_index', 'location_advantage_index', 
        'sales_norm', 'stability_norm', 'growth_norm', 'location_norm', 'cbs_score',
        'ì—‘ìŠ¤ì¢Œí‘œ_ê°’', 'ì™€ì´ì¢Œí‘œ_ê°’', 'í–‰ì •ë™_ì½”ë“œ_ëª…', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…', 'ìƒê¶Œ_ë³€í™”_ì§€í‘œ', 'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…'
    ]
    all_numeric_features = predictions_db.select_dtypes(include=np.number).columns.tolist()
    features = [f for f in all_numeric_features if f not in features_to_exclude]

    background_data = predictions_db[features].fillna(0)
    instance_df = predictions_db[
        (predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)) & 
        (predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code)
    ]
    cbs_features = ['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡', 'ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ', 'íì—…_ë¥ ', 'ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ', 'ê°œì—…_ìœ¨', 'ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì í¬_ìˆ˜', 'ì´_ì§ì¥_ì¸êµ¬_ìˆ˜']
    background_data_cbs = background_data[cbs_features]
    if instance_df.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    instance_to_explain_cbs = instance_df[cbs_features].fillna(0)
    instance_to_explain = instance_df[features].fillna(0)
    if instance_to_explain.empty:
        raise HTTPException(status_code=500, detail="ë¶„ì„í•  ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def calculate_cbs_for_shap_local(X_values: np.ndarray) -> np.ndarray:
        row_df = pd.DataFrame(X_values, columns=features)
        epsilon = 1e-6
        seoul_avg_op_months = row_df['ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ']
        stability_index = (1 - row_df['íì—…_ë¥ ']) * 100 * (row_df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / (seoul_avg_op_months + epsilon))
        growth_index = (row_df['ê°œì—…_ìœ¨'] / (row_df['íì—…_ë¥ '] + epsilon)) * row_df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] * 100
        locational_advantage_index = (row_df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / (row_df['ì í¬_ìˆ˜'] + epsilon)) * (row_df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
        predicted_sales = row_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']
        cbs_scores = (predicted_sales * 0.35) + (stability_index * 0.25) + (growth_index * 0.20) + (locational_advantage_index * 0.20)
        return cbs_scores.to_numpy()

    cbs_explainer = shap.Explainer(calculate_cbs_for_shap_local, background_data_cbs)
    sales_explainer = shap.Explainer(calculate_cbs_for_shap_local, background_data)
    shap_values_cbs = cbs_explainer(instance_to_explain_cbs)
    shap_values_sales = sales_explainer(instance_to_explain)

    cbs_values_instance = shap_values_cbs.values[0]
    sales_values_instance = shap_values_sales.values[0]
    total_impact = np.abs(cbs_values_instance).sum()
    epsilon = 1e-6 

    cbs_results_df = pd.DataFrame({
        'Feature': cbs_features,
        'Actual_Value': instance_to_explain_cbs.iloc[0].values,
        'Mean_Value': background_data_cbs.mean().values,
        'SHAP_Value': cbs_values_instance,
        'Contribution_Percent': (cbs_values_instance / (total_impact + epsilon)) * 100
    }).sort_values(by='SHAP_Value', key=abs, ascending=False).reset_index(drop=True)

    sales_results_df = pd.DataFrame({
        'Feature': background_data.columns,
        'Actual_Value': instance_to_explain.iloc[0],
        'Mean_Value': background_data.mean(),
        'SHAP_Value': shap_values_sales.values[0]
    }).sort_values(by='SHAP_Value', ascending=False)
    
    base_score = shap_values_cbs.base_values[0]
    predicted_score = base_score + cbs_results_df['SHAP_Value'].sum()

    strengths = []
    weaknesses = []
    cbs = []

    dong_name = instance_df.iloc[0]['í–‰ì •ë™_ì½”ë“œ_ëª…']
    industry_name = instance_df.iloc[0]['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…']

    for _, row in cbs_results_df.head(5).iterrows():
        cbs_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f} "
                           f"(í‰ê· ê°’: {row['Mean_Value']:,.0f}, ì˜í–¥ë ¥: {row['Contribution_Percent']:.1f}%)")
        cbs.append(cbs_detail)

    for _, row in sales_results_df.head(5).iterrows():
        sales_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f}  (í‰ê· ê°’: {row['Mean_Value']:,.0f}) ")
        strengths.append(sales_detail)
        
    for _, row in sales_results_df.tail(5).iterrows():
        sales_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f}  (í‰ê· ê°’: {row['Mean_Value']:,.0f}) ")
        weaknesses.append(sales_detail)

    return {
        "dong_name": dong_name,
        "industry_name": industry_name,
        "cbs": cbs,
        "strengths": strengths,
        "weaknesses": weaknesses,
    }
    
@app.get("/api/ai_insight")
def ai_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    insight_data = get_insight(industry_code, dong_code)
    
    def format_list_for_prompt(items: list) -> str:
        return "\n".join([f"- {item}" for item in items])

    cbs_factors_str = format_list_for_prompt(insight_data["cbs"])
    strengths_str = format_list_for_prompt(insight_data["strengths"])
    weaknesses_str = format_list_for_prompt(insight_data["weaknesses"])

    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìƒê¶Œë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ ì¡°ì–¸í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.
    ì•„ë˜ [ë¶„ì„ ì •ë³´]ì™€ [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… ì»¨ì„¤íŒ… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ë¶„ì„ ì •ë³´]
    - ë¶„ì„ ì§€ì—­: {insight_data["dong_name"]}
    - ë¶„ì„ ì—…ì¢…: {insight_data["industry_name"]}

    [í•µì‹¬ ë¶„ì„ ë°ì´í„°]
    1. CBS ì ìˆ˜ ê²°ì • ìš”ì¸ (ì˜í–¥ë ¥ ìˆœ):
    {cbs_factors_str}

    2. ì˜ˆìƒ ë§¤ì¶œì— ê¸ì •ì  ì˜í–¥ì„ ì¤€ ìš”ì¸ (ê°•ì ):
    {strengths_str}

    3. ì˜ˆìƒ ë§¤ì¶œì— ë¶€ì •ì  ì˜í–¥ì„ ì¤€ ìš”ì¸ (ì•½ì ):
    {weaknesses_str}

    [ì‘ì„± ê°€ì´ë“œë¼ì¸]
    1. **ê²°ë¡  ìš”ì•½ (summary):** [ë¶„ì„ ì •ë³´]ì™€ [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ë¥¼ ì¢…í•©í•˜ì—¬ ì´ ìƒê¶Œì˜ í•µì‹¬ íŠ¹ì§•, ê¸°íšŒ, ìœ„í—˜ ìš”ì¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    2. **CBS ê²°ì • ìš”ì¸ ë¶„ì„ (cbs_analysis):** [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ì˜ 'CBS ì ìˆ˜ ê²°ì • ìš”ì¸' ì¤‘ ìƒìœ„ 3ê°€ì§€ê°€ ì´ ìƒê¶Œì˜ ì¢…í•©ì ì¸ ë§¤ë ¥ë„ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì´ìœ ë¥¼ ë“¤ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.
    3. **ê°•ì  ë° ì•½ì  í‰ê°€ (evaluation):** [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ì˜ 'ê°•ì 'ê³¼ 'ì•½ì ' ë°ì´í„°ë¥¼ ê°ê° 2~3ê°€ì§€ì”© í™œìš©í•˜ì—¬, ì‹¤ì œ ì°½ì—… ì‹œ ì–´ë–¤ ì ì„ í™œìš©í•˜ê³  ì–´ë–¤ ì ì„ ë³´ì™„í•´ì•¼ í• ì§€ ë¶„ì„í•©ë‹ˆë‹¤.
    4. **ìµœì¢… ì „ëµ ì œì–¸ (strategy):** ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, ì´ ìƒê¶Œì— ì§„ì…í•˜ë ¤ëŠ” ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
    5. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ, ì¹œì ˆí•˜ê³  ì „ë¬¸ê°€ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [JSON ì¶œë ¥ ê·œì¹™]
    - ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ "summary", "cbs_analysis", "evaluation", "strategy" í‚¤ë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
    - **ë§¤ìš° ì¤‘ìš”**: ê° í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’(value)ì€ ë°˜ë“œì‹œ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¬¸ìì—´(a single string)ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    - **ì ˆëŒ€ë¡œ ê°’ ë¶€ë¶„ì— JSON ê°ì²´ë‚˜ ë¦¬ìŠ¤íŠ¸(`{{}}`, `[]`)ë¥¼ ì¤‘ì²©í•˜ì—¬ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
    """

    try:
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            return { "report": { "summary": "AI ë¶„ì„ ì‹¤íŒ¨", "cbs_analysis": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "evaluation": "ì„œë²„ í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.", "strategy": "" } }

        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": "You are a top commercial district analyst in South Korea. Your response must be in JSON object format."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        ai_response_dict = json.loads(response.choices[0].message.content) #type: ignore
        keys = ["summary", "cbs_analysis", "evaluation", "strategy"]
        default_message = "AIê°€ í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ë¶„ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        ai_interpretation = {key: ai_response_dict.get(key, default_message) for key in keys}

    except Exception as e:
        ai_interpretation = {
            "summary": "AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "cbs_analysis": f"ì˜¤ë¥˜: {e}",
            "evaluation": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "strategy": ""
        }
        
    return { "report": ai_interpretation }

@app.get("/api/stats")
def get_stats(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ"), industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    avg_cbs_score_seoul = predictions_db['cbs_score'].mean()
    dong_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    avg_sales_dong = dong_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'].mean() if not dong_df.empty else 0
    industry_df = predictions_db[predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    avg_sales_industry = industry_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'].mean() if not industry_df.empty else 0

    return {
        "avg_cbs_score_seoul": round(avg_cbs_score_seoul, 1),
        "avg_sales_dong": round(avg_sales_dong),
        "avg_sales_industry": round(avg_sales_industry)
    }

# âœ… ìˆ˜ì • 2: ë¡œì»¬ í™˜ê²½ì—ì„œ ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ì½”ë“œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.
# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)