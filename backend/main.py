import pandas as pd
from typing import Optional, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
from dotenv import load_dotenv
import json
import os
from openai import OpenAI
load_dotenv() 

# --- ì „ì—­ ë³€ìˆ˜ ---
predictions_db: Optional[pd.DataFrame] = None
PREDICTIONS_PATH = "../data/predict_db/predictions_2025.csv"

# --- CBS ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ---

def map_commercial_change_indicator(indicator_name: str) -> int:
    mapping = {'ìƒê¶Œì¶•ì†Œ': 1, 'ì •ì²´': 2, 'í™œì„±í™”': 3, 'ë‹¤ì´ë‚˜ë¯¹': 4}
    return mapping.get(indicator_name, 1)
 
def normalize(series: pd.Series) -> pd.Series:
    """Pandas Seriesë¥¼ 0-100 ì‚¬ì´ ê°’ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    min_val = series.min()
    max_val = series.max()
    if max_val - min_val == 0:
        return pd.Series(50, index=series.index)
    return 100 * (series - min_val) / (max_val - min_val)

def calculate_cbs_scores(df):
    # Step 2: CBS ê° êµ¬ì„± ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
        seoul_avg_op_months = df['ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ']
        df['stability_index'] = (1 - df['íì—…_ë¥ ']) * 100 * (df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / seoul_avg_op_months)
        change_indicator_vals = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…'].apply(map_commercial_change_indicator)
        df['growth_index'] = np.where(
            df['íì—…_ë¥ '] == 0, 0,
            (df['ê°œì—…_ìœ¨'] / df['íì—…_ë¥ ']) * change_indicator_vals * 100
        )
        df['location_advantage_index'] = np.where(
            df['ì í¬_ìˆ˜'] == 0, 0,
            (df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / df['ì í¬_ìˆ˜']) * (df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
        )
    
        # Step 3: ê° ì§€í‘œë¥¼ 0-100ì ìœ¼ë¡œ ì •ê·œí™”
        df['sales_norm'] = normalize(df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'])
        df['stability_norm'] = normalize(df['stability_index'])
        df['growth_norm'] = normalize(df['growth_index'])
        df['location_norm'] = normalize(df['location_advantage_index'])

        # Step 4: ì •ê·œí™”ëœ ì ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ 'ì›ì‹œ' CBS ì ìˆ˜ ê³„ì‚°
        df['cbs_raw_score'] = (
            df['sales_norm'] * 0.35 +
            df['stability_norm'] * 0.25 +
            df['growth_norm'] * 0.20 +
            df['location_norm'] * 0.20
        )        
        # âœ¨ Step 5 (NEW): ìµœì¢… CBS ì ìˆ˜ë¥¼ ë‹¤ì‹œ 0-100ìœ¼ë¡œ ì •ê·œí™”
        df['cbs_score'] = normalize(df['cbs_raw_score'])
        print("âœ… ìµœì¢… CBS ì ìˆ˜ ê³„ì‚° ì™„ë£Œ")
        
        # ì›ì‹œ ì ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œ (ì„ íƒ ì‚¬í•­)
        df = df.drop(columns=['cbs_raw_score'])
        return df

    
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„° ë¡œë“œ ë° ëª¨ë“  ì ìˆ˜ ì‚¬ì „ ê³„ì‚° (ì •ê·œí™” ë¡œì§ ê°œì„ )"""
    global predictions_db, numeric_features
    try:
        df = pd.read_csv(PREDICTIONS_PATH)
        print(f"âœ… '{PREDICTIONS_PATH}'ì—ì„œ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(df)}ê°œ)")
        df.fillna(0, inplace=True)
        growth_map = {'ìƒê¶Œí™•ì¥': 1.5, 'ë‹¤ì´ë‚˜ë¯¹': 1.2, 'ì •ì²´': 1.0, 'ìƒê¶Œì¶•ì†Œ': 0.8}
        df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ'].map(growth_map)
        predictions_db = calculate_cbs_scores(df)
        
        numeric_features = predictions_db.select_dtypes(include=np.number).columns.tolist()
        print(f"âœ… ìˆ«ìí˜• í”¼ì²˜ {len(numeric_features)}ê°œë¥¼ ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        
        print("ğŸš€ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")


    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ì„œë²„ ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        predictions_db = None
    yield
    print("Application Shutdown.")

origins = [
    "http://localhost:5173",
]

# ===== ì•± ìƒì„±, CORS, Pydantic ëª¨ë¸ (ì´ì „ê³¼ ë™ì¼) =====
app = FastAPI(title="HotSpot API", version="0.4", description="ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë° ì •ê·œí™”ëœ CBS ê¸°ë°˜ ì¶”ì²œ API", lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=origins, allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
class RecommendationItem(BaseModel):
    name: str; code: str; cbs_score: float; store_count: int 
class PredictSelectionPayload(BaseModel):
    dong_code: str; industry_code: str

# ===== API ë¼ìš°í„° (í›¨ì”¬ ë‹¨ìˆœí•´ì§) =====
@app.get("/")
def health_check():
    return {"status": "ok", "prediction_data_ready": predictions_db is not None}

@app.post("/predict_by_selection", summary="ì„ íƒí•œ ìƒê¶Œ ë§¤ì¶œ ë° CBS ì ìˆ˜ ì¡°íšŒ")
def predict_by_selection(payload: PredictSelectionPayload):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤(ì˜ˆì¸¡ DB)ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    result_row = predictions_db[
        (predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(payload.dong_code)) &
        (predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == payload.industry_code)
    ]
    
    if result_row.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    data = result_row.iloc[0]

    return {
        "dong_code": payload.dong_code, 
        "industry_code": payload.industry_code,
        "prediction": round(float(data['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']), 1),
        "cbs_score": round(float(data['cbs_score']), 2), # ë¯¸ë¦¬ ê³„ì‚°ëœ CBS ì ìˆ˜ ë°˜í™˜
        "rent": round(float(data['ì„ëŒ€ë£Œ']), 2)
    }

@app.get("/rent_distribution", summary="ì§€ì—­ ë‚´ ì„ëŒ€ë£Œ ë¶„í¬ ë°ì´í„° ì¡°íšŒ")
def get_rent_distribution(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ"), industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 1. í•´ë‹¹ ì§€ì—­(ë™)ì˜ ëª¨ë“  ì„ëŒ€ë£Œ ë°ì´í„° ì¶”ì¶œ
    dong_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    if dong_df.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_code}' ì§€ì—­ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    all_rents = predictions_db['ì„ëŒ€ë£Œ'].dropna()
    if all_rents.empty:
        return {
            "bins": [], "counts": [], "current_rent_bin_index": -1,
            "current_rent": 0, "top_percentile": 50 # ë°ì´í„° ì—†ì„ ì‹œ ì¤‘ê°„ê°’ ë°˜í™˜
        }

    # 2. í˜„ì¬ ì„ íƒí•œ ì—…ì¢…ì˜ íŠ¹ì • ì„ëŒ€ë£Œ ì¡°íšŒ
    current_selection_df = dong_df[dong_df['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    current_rent = current_selection_df.iloc[0].get('ì„ëŒ€ë£Œ', 0) if not current_selection_df.empty else 0

    # 3. âœ¨ ì‹ ê·œ: ìƒìœ„ í¼ì„¼íŠ¸ ê³„ì‚°
    if len(all_rents) > 0:
        # ìì‹ ë³´ë‹¤ ì„ëŒ€ë£Œê°€ ë‚®ì€ ì—…ì¢…ì˜ ìˆ˜ ê³„ì‚°
        count_lower = (all_rents < current_rent).sum()
        # í•˜ìœ„ ë°±ë¶„ìœ„ ê³„ì‚° (0~100)
        percentile_from_bottom = (count_lower / len(all_rents)) * 100
        # ìƒìœ„ ë°±ë¶„ìœ„ë¡œ ë³€í™˜ (e.g., í•˜ìœ„ 90% -> ìƒìœ„ 10%)
        top_percentile = 100.0 - percentile_from_bottom
    else:
        top_percentile = 50.0 # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ê¸°ë³¸ê°’

    # 4. ì„ëŒ€ë£Œ ë°ì´í„°ë¥¼ 10ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
    counts, bins = np.histogram(all_rents, bins=10)

    # 5. í˜„ì¬ ì„ëŒ€ë£Œê°€ ì–´ëŠ êµ¬ê°„ì— ì†í•˜ëŠ”ì§€ ì¸ë±ìŠ¤ ì°¾ê¸°
    current_rent_bin_index = np.digitize(current_rent, bins) - 1
    if current_rent_bin_index == len(counts):
        current_rent_bin_index -= 1

    return {
        "bins": bins.tolist(),
        "counts": counts.tolist(),
        "current_rent_bin_index": int(current_rent_bin_index),
        "current_rent": int(current_rent),
        "top_percentile": round(top_percentile, 1) # ê³„ì‚°ëœ ìƒìœ„ í¼ì„¼íŠ¸ ê°’ì„ ì‘ë‹µì— ì¶”ê°€
    }
    
@app.get("/recommend/regions", summary="ì—…ì¢…ë³„ ìµœì  ì§€ì—­ Top 5 ì¶”ì²œ", response_model=List[RecommendationItem])
def get_top_regions_for_industry(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    filtered_df = predictions_db[predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{industry_code}' ì—…ì¢… ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë¯¸ë¦¬ ê³„ì‚°ëœ cbs_scoreë¡œ ì •ë ¬ë§Œ ìˆ˜í–‰
    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)
    
    return [
        RecommendationItem(name=row['í–‰ì •ë™_ì½”ë“œ_ëª…'], 
                           code=str(row['í–‰ì •ë™_ì½”ë“œ']), 
                           cbs_score=round(row['cbs_score'], 2),
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0) 
        for _, row in top_5.iterrows()
    ]

@app.get("/recommend/industries", summary="ì§€ì—­ë³„ ìµœì  ì—…ì¢… Top 5 ì¶”ì²œ", response_model=List[RecommendationItem])
def get_top_industries_for_region(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    filtered_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_code}' ì§€ì—­ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë¯¸ë¦¬ ê³„ì‚°ëœ cbs_scoreë¡œ ì •ë ¬ë§Œ ìˆ˜í–‰
    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)

    return [
        RecommendationItem(name=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'], 
                           code=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'], 
                           cbs_score=round(row['cbs_score'], 2),
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0)
        for _, row in top_5.iterrows()
    ]

@app.get("/get_insight", summary="ìƒê¶Œ ë¶„ì„ ê°•ì , ì•½ì ")
def get_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    import shap
    
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # --- 1. ë¶„ì„ì— ì‚¬ìš©í•  í”¼ì²˜(feature) ëª©ë¡ ì •ì˜ ---
    features_to_exclude = [
        'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡',
        'stability_index', 'growth_index', 'location_advantage_index', 
        'sales_norm', 'stability_norm', 'growth_norm', 'location_norm', 'cbs_score',
        'ì—‘ìŠ¤ì¢Œí‘œ_ê°’', 'ì™€ì´ì¢Œí‘œ_ê°’', 'í–‰ì •ë™_ì½”ë“œ_ëª…', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…', 'ìƒê¶Œ_ë³€í™”_ì§€í‘œ', 'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…'
    ]
    all_numeric_features = predictions_db.select_dtypes(include=np.number).columns.tolist()
    features = [f for f in all_numeric_features if f not in features_to_exclude]

    # --- 2. ë°°ê²½ ë°ì´í„°(ì „ì²´)ì™€ ë¶„ì„ ëŒ€ìƒ ë°ì´í„°(íŠ¹ì • í–‰) ë¶„ë¦¬ ---
    background_data = predictions_db[features].fillna(0)
    instance_df = predictions_db[
        (predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)) & 
        (predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code)
    ]
    cbs_features = ['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡', 'ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ', 'íì—…_ë¥ ', 'ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ', 'ê°œì—…_ìœ¨', 'ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'ì í¬_ìˆ˜', 'ì´_ì§ì¥_ì¸êµ¬_ìˆ˜']
    background_data_cbs = background_data[cbs_features]
    if instance_df.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    instance_to_explain_cbs = instance_df[cbs_features].fillna(0)
    instance_to_explain = instance_df[features].fillna(0)
    if instance_to_explain.empty:
        raise HTTPException(status_code=500, detail="ë¶„ì„í•  ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # --- 3. SHAP ë¶„ì„ì„ ìœ„í•œ ëª¨ë¸ í•¨ìˆ˜ ì •ì˜ (ìˆ˜ì • ì—†ìŒ) ---
    def calculate_cbs_for_shap_local(X_values: np.ndarray) -> np.ndarray:
        row_df = pd.DataFrame(X_values, columns=features)
        epsilon = 1e-6
        seoul_avg_op_months = row_df['ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ']
        stability_index = (1 - row_df['íì—…_ë¥ ']) * 100 * (row_df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / (seoul_avg_op_months + epsilon))
        growth_index = (row_df['ê°œì—…_ìœ¨'] / (row_df['íì—…_ë¥ '] + epsilon)) * row_df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] * 100
        locational_advantage_index = (row_df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / (row_df['ì í¬_ìˆ˜'] + epsilon)) * (row_df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
        predicted_sales = row_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']
        cbs_scores = (predicted_sales * 0.35) + (stability_index * 0.25) + (growth_index * 0.20) + (locational_advantage_index * 0.20)
        return cbs_scores.to_numpy()

    # --- 4. SHAP ë¶„ì„ ì‹¤í–‰ ---
    cbs_explainer = shap.Explainer(calculate_cbs_for_shap_local, background_data_cbs)
    sales_explainer = shap.Explainer(calculate_cbs_for_shap_local, background_data)
    shap_values_cbs = cbs_explainer(instance_to_explain_cbs)
    shap_values_sales = sales_explainer(instance_to_explain)

    # --- 5. ë¶„ì„ ê²°ê³¼ ì •ë¦¬ ë° í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ìƒì„± (### ìˆ˜ì •ëœ ë¶€ë¶„ ###) ---

    # ë¶„ì„ ëŒ€ìƒì¸ìŠ¤í„´ì˜ SHAP ê°’ ë°°ì—´
    cbs_values_instance = shap_values_cbs.values[0]
    sales_values_instance = shap_values_sales.values[0]

    # ì˜í–¥ë ¥ì˜ ì´í•©(ì ˆëŒ€ê°’ ê¸°ì¤€) ê³„ì‚°
    total_impact = np.abs(cbs_values_instance).sum()
    epsilon = 1e-6 

    cbs_results_df = pd.DataFrame({
        'Feature': cbs_features,
        'Actual_Value': instance_to_explain_cbs.iloc[0].values,
        'Mean_Value': background_data_cbs.mean().values,
        'SHAP_Value': cbs_values_instance,
        'Contribution_Percent': (cbs_values_instance / (total_impact + epsilon)) * 100
    }).sort_values(by='SHAP_Value', key=abs, ascending=False).reset_index(drop=True)

    sales_results_df = pd.DataFrame({
        'Feature': background_data.columns,
        'Actual_Value': instance_to_explain.iloc[0],
        'Mean_Value': background_data.mean(),
        'SHAP_Value': shap_values_sales.values[0]
    }).sort_values(by='SHAP_Value', ascending=False)
    
    base_score = shap_values_cbs.base_values[0]
    predicted_score = base_score + cbs_results_df['SHAP_Value'].sum()

    strengths = []
    weaknesses = []
    cbs = []

    dong_name = instance_df.iloc[0]['í–‰ì •ë™_ì½”ë“œ_ëª…']
    industry_name = instance_df.iloc[0]['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…']

    shap_result_text = f"""- ë¶„ì„ ëŒ€ìƒ: {dong_name} / {industry_name}
    - ê¸°ë³¸ ì ìˆ˜(ì „ì²´ ìƒê¶Œ í‰ê· ): {base_score:,.0f}ì 
    - ìµœì¢… ì˜ˆì¸¡ ì ìˆ˜: {predicted_score:,.0f}ì 
    - cbs ê²°ì • ìš”ì¸
    """

    for _, row in cbs_results_df.head(5).iterrows():
        direction = "ë†’ìŒ" if row['Actual_Value'] > row['Mean_Value'] else "ë‚®ìŒ"
        cbs_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f} "
                           f"(í‰ê· ê°’: {row['Mean_Value']:,.0f}, ì˜í–¥ë ¥: {row['Contribution_Percent']:.1f}%)")
        shap_result_text += "\n- " + cbs_detail
        cbs.append(cbs_detail)

    shap_result_text += "- ê°•ì  Top 5 (ë§¤ì¶œì„ ì˜¬ë¦° ìš”ì¸) -"
    for _, row in sales_results_df.head(5).iterrows():
        direction = "ë†’ìŒ" if row['Actual_Value'] > row['Mean_Value'] else "ë‚®ìŒ"
        sales_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f}  (í‰ê· ê°’: {row['Mean_Value']:,.0f}) ")
        shap_result_text += "\n- " + sales_detail
        strengths.append(sales_detail)
        
    shap_result_text += "- ì•½ì  Top 5 (ë§¤ì¶œì„ ë‚®ì¶˜ ìš”ì¸) -"
    for _, row in sales_results_df.tail(5).iterrows():
        direction = "ë†’ìŒ" if row['Actual_Value'] > row['Mean_Value'] else "ë‚®ìŒ"
        sales_detail = (f"{row['Feature']}: {row['Actual_Value']:,.0f}  (í‰ê· ê°’: {row['Mean_Value']:,.0f}) ")
        shap_result_text += "\n- " + sales_detail
        weaknesses.append(sales_detail)

    return {
        "dong_name": dong_name,
        "industry_name": industry_name,
        "cbs": cbs,
        "strengths": strengths,
        "weaknesses": weaknesses,
        # shap_result_textëŠ” ì´ì œ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ, ë””ë²„ê¹… ë“±ì„ ìœ„í•´ ìœ ì§€
        "shap_result_text": shap_result_text 
    }
    
@app.get("/ai_insight", summary="AI ê¸°ë°˜ ìƒê¶Œ ë¶„ì„ ë¦¬í¬íŠ¸")
def ai_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    insight_data = get_insight(industry_code, dong_code)
    
    def format_list_for_prompt(items: list) -> str:
        """ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì„ ì¤„ë°”ê¿ˆ ë¬¸ìë¡œ ì—°ê²°í•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤."""
        return "\n".join([f"- {item}" for item in items])

    cbs_factors_str = format_list_for_prompt(insight_data["cbs"])
    strengths_str = format_list_for_prompt(insight_data["strengths"])
    weaknesses_str = format_list_for_prompt(insight_data["weaknesses"])

    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìƒê¶Œë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ ì¡°ì–¸í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.
    ì•„ë˜ [ë¶„ì„ ì •ë³´]ì™€ [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… ì»¨ì„¤íŒ… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ë¶„ì„ ì •ë³´]
    - ë¶„ì„ ì§€ì—­: {insight_data["dong_name"]}
    - ë¶„ì„ ì—…ì¢…: {insight_data["industry_name"]}

    [í•µì‹¬ ë¶„ì„ ë°ì´í„°]
    1. CBS ì ìˆ˜ ê²°ì • ìš”ì¸ (ì˜í–¥ë ¥ ìˆœ):
    {cbs_factors_str}

    2. ì˜ˆìƒ ë§¤ì¶œì— ê¸ì •ì  ì˜í–¥ì„ ì¤€ ìš”ì¸ (ê°•ì ):
    {strengths_str}

    3. ì˜ˆìƒ ë§¤ì¶œì— ë¶€ì •ì  ì˜í–¥ì„ ì¤€ ìš”ì¸ (ì•½ì ):
    {weaknesses_str}

    [ì‘ì„± ê°€ì´ë“œë¼ì¸]
    1. **ê²°ë¡  ìš”ì•½ (summary):** [ë¶„ì„ ì •ë³´]ì™€ [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ë¥¼ ì¢…í•©í•˜ì—¬ ì´ ìƒê¶Œì˜ í•µì‹¬ íŠ¹ì§•, ê¸°íšŒ, ìœ„í—˜ ìš”ì¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    2. **CBS ê²°ì • ìš”ì¸ ë¶„ì„ (cbs_analysis):** [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ì˜ 'CBS ì ìˆ˜ ê²°ì • ìš”ì¸' ì¤‘ ìƒìœ„ 3ê°€ì§€ê°€ ì´ ìƒê¶Œì˜ ì¢…í•©ì ì¸ ë§¤ë ¥ë„ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì´ìœ ë¥¼ ë“¤ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.
    3. **ê°•ì  ë° ì•½ì  í‰ê°€ (evaluation):** [í•µì‹¬ ë¶„ì„ ë°ì´í„°]ì˜ 'ê°•ì 'ê³¼ 'ì•½ì ' ë°ì´í„°ë¥¼ ê°ê° 2~3ê°€ì§€ì”© í™œìš©í•˜ì—¬, ì‹¤ì œ ì°½ì—… ì‹œ ì–´ë–¤ ì ì„ í™œìš©í•˜ê³  ì–´ë–¤ ì ì„ ë³´ì™„í•´ì•¼ í• ì§€ ë¶„ì„í•©ë‹ˆë‹¤.
    4. **ìµœì¢… ì „ëµ ì œì–¸ (strategy):** ëª¨ë“  ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, ì´ ìƒê¶Œì— ì§„ì…í•˜ë ¤ëŠ” ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
    5. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ, ì¹œì ˆí•˜ê³  ì „ë¬¸ê°€ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    
    [JSON ì¶œë ¥ ê·œì¹™]
    - ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë“œì‹œ "summary", "cbs_analysis", "evaluation", "strategy" í‚¤ë¥¼ í¬í•¨í•˜ëŠ” JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
    - **ë§¤ìš° ì¤‘ìš”**: ê° í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’(value)ì€ ë°˜ë“œì‹œ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¬¸ìì—´(a single string)ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    - **ì ˆëŒ€ë¡œ ê°’ ë¶€ë¶„ì— JSON ê°ì²´ë‚˜ ë¦¬ìŠ¤íŠ¸(`{{}}`, `[]`)ë¥¼ ì¤‘ì²©í•˜ì—¬ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
    """

    try:
        api_key = os.environ.get("OPENAI_API_KEY")
        
        if not api_key:
            return {
                "report": {
                    "summary": "AI ë¶„ì„ ì‹¤íŒ¨",
                    "cbs_analysis": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "evaluation": "ì„œë²„ í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    "strategy": ""
                }
            }

        client = OpenAI(api_key=api_key)
        
        # â˜…â˜…â˜… API í˜¸ì¶œ ìˆ˜ì •: JSON ëª¨ë“œ í™œì„±í™” â˜…â˜…â˜…
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": "You are a top commercial district analyst in South Korea. Your response must be in JSON object format."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        # OpenAI ì‘ë‹µì´ JSON ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±í•´ì„œ ë°˜í™˜
        ai_response_dict = json.loads(response.choices[0].message.content) #type: ignore
        keys = ["summary", "cbs_analysis", "evaluation", "strategy"]
        default_message = "AIê°€ í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ë¶„ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        ai_interpretation = {key: ai_response_dict.get(key, default_message) for key in keys}
        print("âœ… AI ì»¨ì„¤í„´íŠ¸ ë¶„ì„ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        ai_interpretation = {
            "summary": "AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "cbs_analysis": f"ì˜¤ë¥˜: {e}",
            "evaluation": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "strategy": ""
        }
        
    return {
        "report": ai_interpretation
    }

@app.get("/stats", summary="ì£¼ìš” í†µê³„ ì¡°íšŒ")
def get_stats(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ"), industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # 1. ì„œìš¸ì‹œ ì „ì²´ì˜ í‰ê·  CBS ì ìˆ˜
    avg_cbs_score_seoul = predictions_db['cbs_score'].mean()

    # 2. ì„ íƒëœ ì§€ì—­(ë™)ì˜ ëª¨ë“  ì—…ì¢… í‰ê·  ë§¤ì¶œ
    dong_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    avg_sales_dong = dong_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'].mean() if not dong_df.empty else 0

    # 3. ì„ íƒëœ ì—…ì¢…ì˜ ëª¨ë“  ì§€ì—­ í‰ê·  ë§¤ì¶œ
    industry_df = predictions_db[predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    avg_sales_industry = industry_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'].mean() if not industry_df.empty else 0

    return {
        "avg_cbs_score_seoul": round(avg_cbs_score_seoul, 1),
        "avg_sales_dong": round(avg_sales_dong),
        "avg_sales_industry": round(avg_sales_industry)
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)