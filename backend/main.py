import pandas as pd
from typing import Optional, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import numpy as np
from dotenv import load_dotenv
import os
from openai import OpenAI
load_dotenv() 

# --- ì „ì—­ ë³€ìˆ˜ ---
predictions_db: Optional[pd.DataFrame] = None
PREDICTIONS_PATH = "../data/predict_db/predictions_2025.csv"

# --- CBS ê³„ì‚°ì„ ìœ„í•œ í•¨ìˆ˜ë“¤ (ìˆ˜ì • ì—†ìŒ) ---

def map_commercial_change_indicator(indicator_name: str) -> int:
    mapping = {'ìƒê¶Œì¶•ì†Œ': 1, 'ì •ì²´': 2, 'í™œì„±í™”': 3, 'ë‹¤ì´ë‚˜ë¯¹': 4}
    return mapping.get(indicator_name, 1)
 
def normalize(series: pd.Series) -> pd.Series:
    """Pandas Seriesë¥¼ 0-100 ì‚¬ì´ ê°’ìœ¼ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    min_val = series.min()
    max_val = series.max()
    if max_val - min_val == 0:
        return pd.Series(50, index=series.index)
    return 100 * (series - min_val) / (max_val - min_val)

def calculate_cbs_scores(df):
    # Step 2: CBS ê° êµ¬ì„± ì§€í‘œë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
        seoul_avg_op_months = df['ì„œìš¸_ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· ']
        df['stability_index'] = (1 - df['íì—…_ë¥ ']) * 100 * (df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / seoul_avg_op_months)
        change_indicator_vals = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_ëª…'].apply(map_commercial_change_indicator)
        df['growth_index'] = np.where(
            df['íì—…_ë¥ '] == 0, 0,
            (df['ê°œì—…_ìœ¨'] / df['íì—…_ë¥ ']) * change_indicator_vals * 100
        )
        df['location_advantage_index'] = np.where(
            df['ì í¬_ìˆ˜'] == 0, 0,
            (df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / df['ì í¬_ìˆ˜']) * (df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
        )
    
        # Step 3: ê° ì§€í‘œë¥¼ 0-100ì ìœ¼ë¡œ ì •ê·œí™”
        df['sales_norm'] = normalize(df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡'])
        df['stability_norm'] = normalize(df['stability_index'])
        df['growth_norm'] = normalize(df['growth_index'])
        df['location_norm'] = normalize(df['location_advantage_index'])

        # Step 4: ì •ê·œí™”ëœ ì ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•˜ì—¬ 'ì›ì‹œ' CBS ì ìˆ˜ ê³„ì‚°
        df['cbs_raw_score'] = (
            df['sales_norm'] * 0.35 +
            df['stability_norm'] * 0.25 +
            df['growth_norm'] * 0.20 +
            df['location_norm'] * 0.20
        )        
        # âœ¨ Step 5 (NEW): ìµœì¢… CBS ì ìˆ˜ë¥¼ ë‹¤ì‹œ 0-100ìœ¼ë¡œ ì •ê·œí™”
        df['cbs_score'] = normalize(df['cbs_raw_score'])
        print("âœ… Step 5: ìµœì¢… CBS ì ìˆ˜ ê³„ì‚° ì™„ë£Œ")
        
        # ì›ì‹œ ì ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œ (ì„ íƒ ì‚¬í•­)
        df = df.drop(columns=['cbs_raw_score'])
        return df

    
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„° ë¡œë“œ ë° ëª¨ë“  ì ìˆ˜ ì‚¬ì „ ê³„ì‚° (ì •ê·œí™” ë¡œì§ ê°œì„ )"""
    global predictions_db, numeric_features
    try:
        df = pd.read_csv(PREDICTIONS_PATH)
        print(f"âœ… Step 1: '{PREDICTIONS_PATH}'ì—ì„œ ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(df)}ê°œ)")
        df.fillna(0, inplace=True)
        growth_map = {'ìƒê¶Œí™•ì¥': 1.5, 'ë‹¤ì´ë‚˜ë¯¹': 1.2, 'ì •ì²´': 1.0, 'ìƒê¶Œì¶•ì†Œ': 0.8}
        df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] = df['ìƒê¶Œ_ë³€í™”_ì§€í‘œ'].map(growth_map)
        predictions_db = calculate_cbs_scores(df)
        
        numeric_features = predictions_db.select_dtypes(include=np.number).columns.tolist()
        print(f"âœ… ìˆ«ìí˜• í”¼ì²˜ {len(numeric_features)}ê°œë¥¼ ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        
        print("ğŸš€ ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")


    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ì„œë²„ ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        predictions_db = None
    yield
    print("Application Shutdown.")

origins = [
    "http://localhost:5173",
]

# ===== ì•± ìƒì„±, CORS, Pydantic ëª¨ë¸ (ì´ì „ê³¼ ë™ì¼) =====
app = FastAPI(title="HotSpot API", version="0.4", description="ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë° ì •ê·œí™”ëœ CBS ê¸°ë°˜ ì¶”ì²œ API", lifespan=lifespan)
app.add_middleware(CORSMiddleware, allow_origins=origins, allow_credentials=True, allow_methods=["*"], allow_headers=["*"])
class RecommendationItem(BaseModel):
    name: str; code: str; cbs_score: float; store_count: int 
class PredictSelectionPayload(BaseModel):
    dong_code: str; industry_code: str

# ===== API ë¼ìš°í„° (í›¨ì”¬ ë‹¨ìˆœí•´ì§) =====
@app.get("/")
def health_check():
    return {"status": "ok", "prediction_data_ready": predictions_db is not None}

@app.post("/predict_by_selection", summary="ì„ íƒí•œ ìƒê¶Œ ë§¤ì¶œ ë° CBS ì ìˆ˜ ì¡°íšŒ")
def predict_by_selection(payload: PredictSelectionPayload):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤(ì˜ˆì¸¡ DB)ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    result_row = predictions_db[
        (predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(payload.dong_code)) &
        (predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == payload.industry_code)
    ]
    if result_row.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    data = result_row.iloc[0]
    return {
        "dong_code": payload.dong_code, 
        "industry_code": payload.industry_code,
        "prediction": round(float(data['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']), 1),
        "cbs_score": round(float(data['cbs_score']), 2) # ë¯¸ë¦¬ ê³„ì‚°ëœ CBS ì ìˆ˜ ë°˜í™˜
    }

@app.get("/recommend/regions", summary="ì—…ì¢…ë³„ ìµœì  ì§€ì—­ Top 5 ì¶”ì²œ", response_model=List[RecommendationItem])
def get_top_regions_for_industry(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    filtered_df = predictions_db[predictions_db['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{industry_code}' ì—…ì¢… ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë¯¸ë¦¬ ê³„ì‚°ëœ cbs_scoreë¡œ ì •ë ¬ë§Œ ìˆ˜í–‰
    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)
    
    return [
        RecommendationItem(name=row['í–‰ì •ë™_ì½”ë“œ_ëª…'], 
                           code=str(row['í–‰ì •ë™_ì½”ë“œ']), 
                           cbs_score=row['cbs_score'], 
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0) 
        for _, row in top_5.iterrows()
    ]

@app.get("/recommend/industries", summary="ì§€ì—­ë³„ ìµœì  ì—…ì¢… Top 5 ì¶”ì²œ", response_model=List[RecommendationItem])
def get_top_industries_for_region(dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    filtered_df = predictions_db[predictions_db['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)]
    if filtered_df.empty:
        raise HTTPException(status_code=404, detail=f"'{dong_code}' ì§€ì—­ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë¯¸ë¦¬ ê³„ì‚°ëœ cbs_scoreë¡œ ì •ë ¬ë§Œ ìˆ˜í–‰
    top_5 = filtered_df.sort_values(by='cbs_score', ascending=False).head(5)

    return [
        RecommendationItem(name=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'], 
                           code=row['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'], 
                           cbs_score=row['cbs_score'], 
                           store_count=int(row['ì í¬_ìˆ˜']) if pd.notna(row['ì í¬_ìˆ˜']) else 0)
        for _, row in top_5.iterrows()
    ]

@app.get("/get_insight", summary="ìƒê¶Œ ë¶„ì„ ê°•ì , ì•½ì ")
def get_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    import shap
    
    if predictions_db is None:
        raise HTTPException(status_code=503, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    df = predictions_db.copy()
    df = df[(df['í–‰ì •ë™_ì½”ë“œ'] == int(dong_code)) & (df['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ'] == industry_code)]
    if df.empty:
        raise HTTPException(status_code=404, detail="ì„ íƒí•œ ì§€ì—­ê³¼ ì—…ì¢…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    df.fillna(0, inplace=True)
    features_to_exclude = [
        'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡', 'ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡',
        # CBS ê³„ì‚°ì— ì‚¬ìš©ëœ ì¤‘ê°„ ì§€í‘œ ë° ìµœì¢… ì ìˆ˜ë„ ì œì™¸í•˜ëŠ” ê²ƒì´ ë¶„ì„ì˜ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
        'stability_index', 'growth_index', 'location_advantage_index', 
        'sales_norm', 'stability_norm', 'growth_norm', 'location_norm', 'cbs_score'
    ]
    
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    features = [f for f in numeric_cols if f not in features_to_exclude]
    X = df[features]
    
    if X.empty or len(X.columns) == 0:
        raise HTTPException(status_code=500, detail="ë¶„ì„í•  ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def calculate_cbs_for_shap_local(X_values: np.ndarray) -> np.ndarray:
        # ì»¬ëŸ¼ ì´ë¦„ìœ¼ë¡œ ì „ì—­ ë³€ìˆ˜ ëŒ€ì‹  í˜„ì¬ ë¶„ì„ ëŒ€ìƒì¸ 'X.columns'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        row_df = pd.DataFrame(X_values, columns=X.columns)
        
        epsilon = 1e-6 # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€
        
        # seoul_avg_op_monthsê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì˜ í‰ê· ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ì•ˆì „í•œ ê¸°ë³¸ê°’ì„ ì„¤ì •
        seoul_avg_op_months = predictions_db['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '].mean()  # type: ignore
        if seoul_avg_op_months == 0: seoul_avg_op_months = 1

        stability_index = (1 - row_df['íì—…_ë¥ ']) * 100 * (row_df['ìš´ì˜_ì˜ì—…_ê°œì›”_í‰ê· '] / seoul_avg_op_months)
        growth_index = (row_df['ê°œì—…_ìœ¨'] / (row_df['íì—…_ë¥ '] + epsilon)) * row_df['ìƒê¶Œ_ë³€í™”_ê°€ì¤‘ì¹˜'] * 100
        locational_advantage_index = (row_df['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] / (row_df['ì í¬_ìˆ˜'] + epsilon)) * (row_df['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜'] / 10000) * 0.1
        predicted_sales = row_df['ì í¬ë‹¹_ë§¤ì¶œ_ê¸ˆì•¡_ì˜ˆì¸¡']
        
        cbs_scores = (predicted_sales * 0.35) + (stability_index * 0.25) + (growth_index * 0.20) + (locational_advantage_index * 0.20)
        return cbs_scores.to_numpy() # ê²°ê³¼ë¥¼ numpy ë°°ì—´ë¡œ ë°˜í™˜

    instance_to_explain = X.iloc[[0]]
    # ìˆ˜ì •ëœ local í•¨ìˆ˜ë¥¼ Explainerì— ì „ë‹¬í•©ë‹ˆë‹¤.
    explainer = shap.Explainer(calculate_cbs_for_shap_local, X)
    shap_values = explainer(instance_to_explain)
    
    results_df = pd.DataFrame({
        'Feature': X.columns,
        'Actual_Value': instance_to_explain.iloc[0],
        'Mean_Value': X.mean(),
        'SHAP_Value': shap_values.values[0]
    }).sort_values(by='SHAP_Value', ascending=False)
    strengths = []
    weaknesses = []
    shap_result_text = f"""- ë¶„ì„ ëŒ€ìƒ: {dong_code} / {industry_code}
    - ê¸°ë³¸ ì ìˆ˜(í‰ê·  CBS): {shap_values.base_values[0]:,.0f}
    - ìµœì¢… ì˜ˆì¸¡ CBS ì ìˆ˜: {explainer.model(instance_to_explain.values)[0]:,.0f}
    - ê°•ì  Top 5 (ì ìˆ˜ë¥¼ ì˜¬ë¦° ìš”ì¸):
    """
    
    for _, row in results_df.head(5).iterrows():
        direction = "í‰ê· ë³´ë‹¤ ë†’ìŒ" if row['Actual_Value'] > row['Mean_Value'] else "í‰ê· ë³´ë‹¤ ë‚®ìŒ"
        strengths.append(f"  - {row['Feature']}: {row['Actual_Value']:,.2f} ({direction})\n")
        shap_result_text += f"  - {row['Feature']}: {row['Actual_Value']:,.2f} ({direction})\n"
        
    shap_result_text += "- ì•½ì  Top 5 (ì ìˆ˜ë¥¼ ë‚´ë¦° ìš”ì¸):\n"
    for _, row in results_df.tail(5).sort_values(by='SHAP_Value', ascending=True).iterrows():
        direction = "í‰ê· ë³´ë‹¤ ë†’ìŒ" if row['Actual_Value'] > row['Mean_Value'] else "í‰ê· ë³´ë‹¤ ë‚®ìŒ"
        weaknesses.append(f"  - {row['Feature']}: {row['Actual_Value']:,.2f} ({direction})\n")
        shap_result_text += f"  - {row['Feature']}: {row['Actual_Value']:,.2f} ({direction})\n"

    return {
        "strengths": strengths,
        "weaknesses": weaknesses,
        "shap_result_text": shap_result_text,
    }
    
@app.get("/ai_insight", summary="AI ê¸°ë°˜ ìƒê¶Œ ë¶„ì„ ë¦¬í¬íŠ¸")
def ai_insight(industry_code: str = Query(..., description="ì„œë¹„ìŠ¤ ì—…ì¢… ì½”ë“œ"), dong_code: str = Query(..., description="í–‰ì •ë™ ì½”ë“œ")):
    insight = get_insight(industry_code, dong_code)
    shap_result_text = insight["shap_result_text"]
    prompt = f"""
    ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìƒê¶Œë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ ì¡°ì–¸í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.
    ì•„ë˜ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ìµœì¢… ì»¨ì„¤íŒ… ì˜ê²¬ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ë¶„ì„ ë°ì´í„°]
    {shap_result_text}

    [ì‘ì„± ê°€ì´ë“œë¼ì¸]
    1. **ê²°ë¡  ìš”ì•½:** ì´ ìƒê¶Œì˜ í•µì‹¬ íŠ¹ì§•ê³¼ ê¸°íšŒ/ìœ„í—˜ ìš”ì¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.
    2. **ê°•ì  ë¶„ì„:** ì ìˆ˜ë¥¼ ì˜¬ë¦° ê°€ì¥ ì¤‘ìš”í•œ ìš”ì¸ 2~3ê°€ì§€ë¥¼ ì„ íƒí•´,
    - (a) êµ¬ì²´ì ì¸ ë°ì´í„° ì§€í‘œ ì„¤ëª… â†’
    - (b) í•´ë‹¹ ì§€í‘œê°€ ì°½ì—…ìì—ê²Œ ì–´ë–¤ ì˜ë¯¸ê°€ ìˆëŠ”ì§€ í•´ì„ â†’
    - (c) ì‹¤ì œ ì „ëµì  ì‹œì‚¬ì  ì œì‹œ
    ì˜ êµ¬ì¡°ë¡œ ê°ê° ì„œìˆ í•©ë‹ˆë‹¤.
    3. **ì•½ì  ë¶„ì„:** ì ìˆ˜ë¥¼ ë‚´ë¦° ê°€ì¥ ì¤‘ìš”í•œ ìš”ì¸ 2~3ê°€ì§€ë¥¼ ì„ íƒí•´,
    ë™ì¼í•˜ê²Œ (a) ì§€í‘œ â†’ (b) ì˜ë¯¸ â†’ (c) ì‹œì‚¬ì  êµ¬ì¡°ë¡œ ìì„¸íˆ ë¶„ì„í•©ë‹ˆë‹¤.
    4. **ìµœì¢… ì „ëµ ì œì–¸:** ìœ„ ë¶„ì„ì„ ì¢…í•©í•˜ì—¬, ì´ ìƒê¶Œì— ì§„ì…í•˜ë ¤ëŠ” ì˜ˆë¹„ ì°½ì—…ìì—ê²Œ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì„ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•©ë‹ˆë‹¤.
    5. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ, ì¹œì ˆí•˜ê³  ì „ë¬¸ê°€ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    # â˜…â˜…â˜… ìµœì¢… ìˆ˜ì •ëœ ë¶€ë¶„ â˜…â˜…â˜…
    # --- OpenAI API í˜¸ì¶œ ---
    try:
        # os.environ.get()ì„ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        api_key = os.environ.get("OPENAI_API_KEY")
        
        if not api_key:
            # í™˜ê²½ ë³€ìˆ˜ì— í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ê²½ê³  ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
            ai_interpretation = "OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ 'export OPENAI_API_KEY=\"sk-...\"' ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
        else:
            client = OpenAI(api_key=api_key) # type: ignore
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ìƒê¶Œë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
            )
            ai_interpretation = response.choices[0].message.content
            print("âœ… 7. AI ì»¨ì„¤í„´íŠ¸ ë¶„ì„ì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        ai_interpretation = f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìë™ í•´ì„ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"
        
    return {
        "report": ai_interpretation
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)